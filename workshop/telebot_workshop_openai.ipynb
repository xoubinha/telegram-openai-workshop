{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "**User Interaction Demo**\n",
    "\n",
    "In this demonstration, you'll create the first iteration of your interactive chatbot, designed to enhance your workshop experience. The bot will initiate a conversation paving the way for exploration into various interaction methods.\n",
    "\n",
    "Let's dive in:\n",
    "\n",
    "1. **Welcome to the Chatbot Workshop!**\n",
    "   - The bot will greet you and set the stage for our interactive session.\n",
    "2. **Workshop Check-In: Share Your Thoughts**\n",
    "   - The bot will prompt you to share your thoughts on the workshop and give you different options. Select the one that adjust better to you and explore the different ways your chatbot can respond.\n",
    "3. **Dynamic Responses**\n",
    "   - Discover how the bot adapts its replies based on your input. Whether you're finding the workshop excellent, facing challenges, or have other thoughts, the bot is ready to engage.\n",
    "4. **Good bye Responses**\n",
    "   - Once you're done, say good bye to the bot and it will reply to you!\n",
    "\n",
    "This interactive demo serves as a glimpse into the versatility of our chatbot, showcasing its ability to dynamically respond to user input. Enjoy the exploration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code explanation\n",
    "Let's break down its key functionalities so it is easier to follow:\n",
    "\n",
    "1. **Welcome and Goodbye Commands:**\n",
    "   - The `send_welcome` function responds to the \"/start\" and \"/hi\" commands with a welcome message and prompts the user for their name. It then registers the `process_name_step` function to handle the next step.\n",
    "   - The `send_goodbye` function responds to \"/end\" and \"/bye\" commands with a goodbye message.\n",
    "\n",
    "```python\n",
    "@bot.message_handler(commands=['start', 'hi'])\n",
    "def send_welcome(message: telebot.types.Message):\n",
    "    # ... (explained above)\n",
    "\n",
    "@bot.message_handler(commands=['end', 'bye'])\n",
    "def send_goodbye(message: telebot.types.Message):\n",
    "    # ... (explained above)\n",
    "```\n",
    "\n",
    "2. **User Name Input Processing:**\n",
    "   - The `process_name_step` function processes the user's name input, creates a User object, and stores it in the `user_dict` dictionary. It then sets up a reply message asking about the workshop status and registers the `process_workshop_step` function to handle the next step.\n",
    "\n",
    "```python\n",
    "def process_name_step(message: telebot.types.Message):\n",
    "    # ... (explained above)\n",
    "```\n",
    "\n",
    "3. **Workshop Status Input Processing:**\n",
    "   - The `process_workshop_step` function processes the user's workshop status input and responds accordingly based on the chosen option. It also prompts the user to send different types of files and continue the demo.\n",
    "  \n",
    "```python\n",
    "def process_workshop_step(message: telebot.types.Message):\n",
    "    # ... (explained above)\n",
    "```\n",
    "\n",
    "4. **Detecting Message Content Type:**\n",
    "   - The `detects_message_content_type` function detects and replies to the type of content the user sends, including text, audio, document, photo, sticker, video, voice, location, and contact.\n",
    "\n",
    "```python\n",
    "@bot.message_handler(content_types=['text', 'audio', 'document', 'photo', 'sticker', 'video', 'voice', 'location', 'contact'])\n",
    "def detects_message_content_type(message):\n",
    "    # ... (explained above)\n",
    "```\n",
    "\n",
    "Overall, this script sets up a basic interactive chatbot that welcomes users, gathers information about the workshop, and handles various types of user inputs. It's a foundation that can be expanded upon for more complex interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import telebot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOT_TOKEN = \"6445003406:AAEy5FEj2n1PmQg8Q_7x1IAnQuFgZs11URQ\"\n",
    "bot = telebot.TeleBot(BOT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_dict = {}\n",
    "\n",
    "class User:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.talk_status = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=['start', 'hi'])\n",
    "def send_welcome(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Respond to the '/start' and '/hi' commands with a welcome message.\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object representing the user's command.\n",
    "    \"\"\"\n",
    "    welcome_message = \"<the-welcome-message-you-want-your-bot-to-say>, what's your name?\"\n",
    "    bot.reply_to(message, welcome_message)\n",
    "    bot.register_next_step_handler(message, process_name_step)\n",
    "\n",
    "\n",
    "@bot.message_handler(commands=['end', 'bye'])\n",
    "def send_goodbye(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Respond to the '/end' and '/bye' commands with a welcome message.\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object representing the user's command.\n",
    "    \"\"\"\n",
    "    goodbye_message = \"<the-good-bye-message-you-want-your-bot-to-say>\"\n",
    "    bot.reply_to(message, goodbye_message)\n",
    "\n",
    "\n",
    "def process_name_step(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Process the user's name input and set up the next step.\n",
    "\n",
    "    Args:\n",
    "        message (Message): The user's message.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chat_id = message.chat.id\n",
    "        name = message.text\n",
    "        user = User(name)\n",
    "        user_dict[chat_id] = user\n",
    "\n",
    "        markup = telebot.types.ReplyKeyboardMarkup(one_time_keyboard=True)\n",
    "        markup.add('<option-1>', '<option-2>', '<option-3>')\n",
    "\n",
    "        reply_message = f\"Hey, {name}! How's the workshop going?\"\n",
    "        msg = bot.reply_to(message, reply_message, reply_markup=markup)\n",
    "\n",
    "        bot.register_next_step_handler(msg, process_workshop_step)\n",
    "    except Exception as e:\n",
    "        bot.reply_to(message, \"Oopsie, there's been a problem! Let your instructors know so they can help you\")\n",
    "\n",
    "def process_workshop_step(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Process the user's talk status input and respond accordingly.\n",
    "\n",
    "    Args:\n",
    "        message (Message): The user's message.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        chat_id = message.chat.id\n",
    "        workshop_status = message.text\n",
    "        user = user_dict.get(chat_id)\n",
    "\n",
    "        if user:\n",
    "            if workshop_status=='<option-1>':\n",
    "                msg = bot.send_message(\n",
    "                    chat_id, f\"<The-message-you-want-to-send-your-user-if-they-chose-option-1>\")\n",
    "            elif workshop_status=='<option-2>':\n",
    "                msg = bot.send_message(\n",
    "                    chat_id, f\"<The-message-you-want-to-send-your-user-if-they-chose-option-2>\")\n",
    "            elif workshop_status=='<option-3>':\n",
    "                msg = bot.send_message(\n",
    "                    chat_id, f\"<The-message-you-want-to-send-your-user-if-they-chose-option-3>\")\n",
    "            bot.send_message(chat_id, \"Let's see now how good I am at detecting different content types, send me different type of files\")\n",
    "\n",
    "    except Exception as e:\n",
    "        bot.reply_to(message, \"Oopsie, there's been a problem! Let your instructors know so they can help you\")\n",
    "\n",
    "@bot.message_handler(content_types=['audio', 'document', 'photo', 'sticker', 'video', 'voice', 'location', 'contact'])\n",
    "def detects_message_content_type(message):\n",
    "    \"\"\"\n",
    "    Detects imessage_content_type. The content type content_type can be one of the following strings:\n",
    "    text, audio, document, photo, sticker, video, video_note, voice, location, contact...\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object sent by the user.\n",
    "    \"\"\"\n",
    "    content_type = message.content_type\n",
    "    bot.reply_to(message, f\"You've sent me a file of type: {content_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Intelligence to the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Understanding why OpenAI + Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load with Langchain OpenAI Chat model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "llm = ChatOpenAI(model_name=model_name, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **ChatOpenAI** to chat with OpenAI GPT. We must send a list of messages\n",
    "- SystemMessage: The system context, usually encapsulates the behavior of the agent\n",
    "- HumanMessage: Message from the user\n",
    "- AIMessage: Message from the assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that translates English to French.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Translate this sentence from English to French. I love programming.\"\n",
    "    ),\n",
    "]\n",
    "ai_message = llm(messages)\n",
    "print(ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important note is that GPT does not have memory, each call must be self-contained.\n",
    "\n",
    "If we as users send a new message or question to OpenAI related to the previous answers or questions, we will see how **Open AI Chat is not aware of previous interactions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [    \n",
    "    HumanMessage(\n",
    "        content=\"Translate again the previous sentence with other words\"\n",
    "    )\n",
    "]\n",
    "llm(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to provide the history of the conversation so that the new answer has all the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that translates English to French.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Translate this sentence from English to French. I love programming.\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=ai_message.content\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Translate again the previous sentence with other words\"\n",
    "    )\n",
    "]\n",
    "ai_message_2 = llm(messages)\n",
    "print(ai_message_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add functions to the Telegram Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.conversation_utils import generate_conversation, conversate, end_conversation\n",
    "from utils.conversation_utils import DEFAULT_SYSTEM_PROMPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different conversations must be managed by storing them separately. If not, all chats with different users will build single chat history, where responses would not make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = {}\n",
    "prompts = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(commands=[\"start_conversation\"])\n",
    "def open_conversation(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Respond to the commands with a welcome message.\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object representing the user's command.\n",
    "    \"\"\"\n",
    "    user_id = message.chat.id\n",
    "    end_conversation(user_id, conversations)\n",
    "    if len(message.text.split(\" \")) > 1:\n",
    "        system_prompt = message.text.split(\" \", 1)[1]\n",
    "    else:\n",
    "        system_prompt = DEFAULT_SYSTEM_PROMPT\n",
    "    prompts[user_id] = system_prompt\n",
    "    welcome_message = \"Hola, a partir de ahora estarÃ¡s hablando con un bot inteligente con el siguiente contexto:\\n------%s\\n------\\nEscribe mensaje para mantener una conversaciÃ³n\" %system_prompt\n",
    "    bot.reply_to(message, welcome_message)\n",
    "\n",
    "\n",
    "@bot.message_handler(commands=[\"end_conversation\"])\n",
    "def close_conversation(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Respond to the commands with a goodbye message.\n",
    "\n",
    "    Args:\n",
    "        message (telebot.types.Message): The message object representing the user's command.\n",
    "    \"\"\"\n",
    "    user_id = message.chat.id\n",
    "    end_conversation(user_id, conversations)\n",
    "    goodbye_message = \"Ya no poseo inteligencia generativa, si quieres volver a aÃ±adirla, envÃ­a '/start_conversation' Â¡nos vemos pronto! ðŸ˜‰\"\n",
    "    bot.reply_to(message, goodbye_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@bot.message_handler(content_types=[\"text\"])\n",
    "def process_openai_step(message: telebot.types.Message):\n",
    "    \"\"\"\n",
    "    Process the message and respond using OpenAI\n",
    "\n",
    "    Args:\n",
    "        message (Message): The user's message.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        user_id = message.chat.id\n",
    "        message_text = message.text\n",
    "\n",
    "        reply_text = conversate(user_id, conversations, message_text, system_prompt=prompts.get(user_id))\n",
    "        msg = bot.reply_to(message, reply_text)\n",
    "\n",
    "    except Exception as e:\n",
    "        bot.reply_to(message, f'Upsi, ha debido de haber algÃºn problema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.enable_save_next_step_handlers(delay=2)\n",
    "bot.load_next_step_handlers()\n",
    "bot.infinity_polling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you've enjoyed this demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycones-demos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
